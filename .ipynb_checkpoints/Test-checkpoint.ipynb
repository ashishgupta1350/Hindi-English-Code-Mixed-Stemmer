{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "try:\n",
    "    import nltk\n",
    "except:\n",
    "    print(\"First install NLTK using pip install nltk command\")\n",
    "    exit()\n",
    "try:\n",
    "    import gensim\n",
    "    from gensim import corpora, models, similarities\n",
    "except:\n",
    "    print(\"First install Gensim using pip install nltk command\")\n",
    "    exit()\n",
    "\n",
    "    \n",
    "class Stemmer:\n",
    "    w2vModel = None\n",
    "    sensitivity = 10\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, modelLocation= \"w2vModel\"):\n",
    "        try:\n",
    "            self.w2vModel = gensim.models.Word2Vec.load(modelLocation)\n",
    "        except:\n",
    "            print(\"Could not locate the w2vModel file in the directory : \"+(modelLocation))\n",
    "    \n",
    "        \n",
    "    \n",
    "    #  ----------- Stemming functions -----------\n",
    "    \n",
    "    \n",
    "    # takes a word and removes the repeated occurance of characters in that word\n",
    "    # outputs word without repeat consecutive occurance of the word\n",
    "    def RepetitionStemmer(self, word):\n",
    "        # find repeted occurence of letters in a word\n",
    "        # remove the occurence \n",
    "        i=0\n",
    "        newWord = ''\n",
    "        while(i <len(word)):\n",
    "            c = word[i]\n",
    "            newWord+=c\n",
    "            while(i<len(word) and word[i] == c):\n",
    "                i=i+1\n",
    "\n",
    "        return newWord\n",
    "\n",
    "    # takes a word2vec model, word and nWords(to run most similar on - higher the better but slower)\n",
    "    # output the list of words similar to that word ( including that word passed through repetition stemmer)\n",
    "    def WordEmbeddingStemmer(self, w2vModel, word, nWords = 10):\n",
    "\n",
    "        try:\n",
    "            similarWordsList =[w2vModel.wv.most_similar(word, topn = nWords )[i][0] for i in range(10)]\n",
    "        except:\n",
    "            return RepetitionStemmer(word)\n",
    "\n",
    "        word = RepetitionStemmer(word)\n",
    "\n",
    "        outputList = []\n",
    "        for similarWord in similarWordsList:\n",
    "            stemmSimilarWord = RepetitionStemmer(similarWord)\n",
    "            w0 = word\n",
    "            w1 = word[:-1]\n",
    "            sw0 = stemmSimilarWord\n",
    "            sw1 = stemmSimilarWord[:-1]\n",
    "\n",
    "            if (sw0 in w0) or( w0 in sw0) or (sw1 in w0) or (w1 in sw0):\n",
    "                if(len(stemmSimilarWord)<len(word)):\n",
    "                    outputList.append(stemmSimilarWord)\n",
    "                else:\n",
    "                    outputList.append(word)\n",
    "        if len(outputList) == 0:\n",
    "            outputList.append(word)\n",
    "        return outputList[0]\n",
    "    \n",
    "    # stemmers\n",
    "    def stemWord(self, word):\n",
    "        return WordEmbeddingStemmer(self.w2vModel, word)\n",
    "    \n",
    "    def stemListOfWords(self, listOfWords):\n",
    "        return [WordEmbeddingStemmer(self.w2vModel, word) for word in listOfWords]\n",
    "    \n",
    "    def stem2dListOfWords(self, listOfWords2d):\n",
    "        output = []\n",
    "        for sentenceOfWords in listOfWords2d:\n",
    "            output.append([WordEmbeddingStemmer(self.w2vModel, word) for word in sentenceOfWords])\n",
    "        return output\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
